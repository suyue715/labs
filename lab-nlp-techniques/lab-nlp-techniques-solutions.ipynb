{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Techniques Lab\n",
    "\n",
    "In this lab, we'll be practicing a set of advanced NLP techniques using tweets on airline satisfaction ([originally from Kaggle](https://www.kaggle.com/crowdflower/twitter-airline-sentiment/data)).\n",
    "\n",
    "The first section asks you to perform LDA on the dataset to summarize the body of tweets. The second section will focus on using this data to predict the sentiment of a given tweet.\n",
    "\n",
    "Import the data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14640, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/Tweets.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this data to do the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use LDA to identify topics in the tweets\n",
    "\n",
    "Pick a number of topics between 5-20 and use LDA to summarize the corpus of tweets. Print out the top 25 most frequently occuring words in each topic. Do the topics appear cohesive to you? What predominant trends can you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardharris/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "ve trying change days seats 30 10 book times doesn miles website info time air minutes make ago credit online travel way need called available \n",
      "\n",
      "Topic 1\n",
      "guys aa jfk want response line said better great delays free http status making terrible hung try year san start looking gave away option asked \n",
      "\n",
      "Topic 2\n",
      "gate tonight waiting agent answer clt understand isn departure time ground delayed sitting worse 200 busy waited tarmac wouldn counting changes cool automated hope las \n",
      "\n",
      "Topic 3\n",
      "united plane new hrs crew won http airlines rude fleek does phl able sitting come say update voucher sorry fail planes stop american fly horrible \n",
      "\n",
      "Topic 4\n",
      "americanair flight usairways cancelled united help hours hold flightled thanks amp just need bag flights got late today phone tomorrow weather did number flighted day \n",
      "\n",
      "Topic 5\n",
      "united airline home bags worst http bad customers staff amp time sure says tell fleet pay really ve experience app ok money flying helpful good \n",
      "\n",
      "Topic 6\n",
      "jetblue southwestair usairways flight service customer thank thanks delayed just hour going delay united long like time boarding best care think flying nice flights rebook \n",
      "\n",
      "Topic 7\n",
      "united ticket right good seat night connection dca class flight plane ord person leave 15 couldn airways passengers didn let ewr point sit help possible \n",
      "\n",
      "Topic 8\n",
      "http wait yes dfw time tried fly dallas calling attendant look work southwest direct min vegas big destinationdragons 45 scheduled virginamerica im lol houston award \n",
      "\n",
      "Topic 9\n",
      "don ll getting love miss know http leaving reason fly hey issues want hard week loyal apology soon sunday fault situation pm sending crazy spoke \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "cv.fit(df['text'])\n",
    "X = cv.transform(df['text'])\n",
    "feature_names = cv.get_feature_names()\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=10)\n",
    "lda.fit(X)\n",
    "\n",
    "results = pd.DataFrame(lda.components_,\n",
    "                      columns=feature_names)\n",
    "\n",
    "for topic in range(10):\n",
    "    print('Topic', topic)\n",
    "    word_list = results.T[topic].sort_values(ascending=False).index\n",
    "    print(' '.join(word_list[0:25]), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Instructor answer:\n",
    "\n",
    "Looks like there are some trends, some topics discuss baggage or airline delays, while others seem to focus on just one or two specific companies.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus LDA Question (Tackle if you have time / interest)\n",
    "\n",
    "Using the `.transform()` method on LDA on the data you fed it will return back a numpy array of shape `(n_rows, n_topics)`. The value in each column will identify the probability that the row in question belongs to that topic. For example, if we were looking at a row of data and an LDA model for three topics, we might see the following:\n",
    "\n",
    "```python\n",
    "lda.transform(row_of_data)\n",
    ">> [[ 0.02, 0.97, 0.01 ]]\n",
    "```\n",
    "\n",
    "This would suggest that for that row of data, it is most likely to be in the second topic (compared to the first or third topic).\n",
    "\n",
    "As a bonus challenge, try the two following questions:\n",
    "\n",
    "1. For each topic, which tweet most exemplifies (or is most likely to belong to that topic?)\n",
    "2. Find a recent tweet at an airline that you have used. Can you use the model you have currently to identify what topic does it belongs to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0\n",
      "[[ '@VirginAmerica did you know that suicide is the second leading cause of death among teens 10-24'\n",
      "  0.9249971729973999]]\n",
      "\n",
      "\n",
      "topic 1\n",
      "[[ '@VirginAmerica you guys messed up my seating.. I reserved seating with my friends and you guys gave my seat away ... ðŸ˜¡ I want free internet'\n",
      "  0.9399980799833922]]\n",
      "\n",
      "\n",
      "topic 2\n",
      "[[ '@united - tick, tock, tick, tock, it is rapidly approaching the next dream departure of 1:45pm. When is the next fantasy departure time??'\n",
      "  0.78405427730716]]\n",
      "\n",
      "\n",
      "topic 3\n",
      "[[ '@united how can you not know the weight of our plane after us sitting on the plane for 2.5 hrs? Not convinced your company is safe for flt.'\n",
      "  0.9249936866887448]]\n",
      "\n",
      "\n",
      "topic 4\n",
      "[[ '@VirginAmerica can u help this ðŸ‘¸ @FreyaBevan_Fund needs urgent treatment inðŸ‡ºðŸ‡¸2y old battling cancer could u help with flights ðŸ’—#freyasfund'\n",
      "  0.9357105009036262]]\n",
      "\n",
      "\n",
      "topic 5\n",
      "[[ '@VirginAmerica has getaway deals through May, from $59 one-way. Lots of cool cities http://t.co/tZZJhuIbCH #CheapFlights #FareCompare'\n",
      "  0.9307640651406944]]\n",
      "\n",
      "\n",
      "topic 6\n",
      "[[ '@VirginAmerica I like the customer service but a 40 min delay just for connecting passengers seems too long. VA370'\n",
      "  0.930764530034115]]\n",
      "\n",
      "\n",
      "topic 7\n",
      "[[ '@VirginAmerica - Let 2 scanned in passengers leave the plane than told someone to remove their bag from 1st class bin? #uncomfortable'\n",
      "  0.9357088978901471]]\n",
      "\n",
      "\n",
      "topic 8\n",
      "[[ '@VirginAmerica I have 2d and 3d embossed badges and patches superior to the ones you are currently using. \\nhttp://t.co/3fq3XElbOn'\n",
      "  0.9307682327027853]]\n",
      "\n",
      "\n",
      "topic 9\n",
      "[[\"@VirginAmerica do you miss me? Don't worry we'll be together very soon.\"\n",
      "  0.8714120136102915]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bonus question 1\n",
    "\n",
    "topic_names = ['topic %s' % topic for topic in range(10)]\n",
    "\n",
    "results = pd.DataFrame(lda.transform(X),\n",
    "                      columns=topic_names)\n",
    "joined = df[['tweet_id', 'text']].join(results)\n",
    "for topic in topic_names:\n",
    "    print(topic)\n",
    "    print(joined.sort_values(by=topic, ascending=False)[['text', topic]].head(1).values)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    topic 0   topic 1   topic 2   topic 3   topic 4  topic 5   topic 6  \\\n",
      "0  0.007694  0.007692  0.161533  0.100286  0.453558  0.16154  0.084616   \n",
      "\n",
      "    topic 7   topic 8   topic 9  \n",
      "0  0.007694  0.007694  0.007692  \n"
     ]
    }
   ],
   "source": [
    "# Bonus question 2\n",
    "\n",
    "tweet = ['@SouthwestAir screwed up my booking and now my gramma can\\'t make it home for Thanksgiving . We booked a Senior Fare in her name and it got swtiched to mine. Plase help us get maw-maw home #southwestairlines']\n",
    "\n",
    "tweet_transformed = cv.transform(tweet)\n",
    "results = pd.DataFrame(lda.transform(tweet_transformed),\n",
    "                      columns=topic_names)\n",
    "print(results)\n",
    "\n",
    "# Looks like mostly related to topic 1 in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use NLP to predict the sentiment of tweets\n",
    "\n",
    "In this section, please use any of the NLP techniques that we have covered over the last two days to best predict whether a tweet has a negative sentiment or not. Transformation code for your target variable is below.\n",
    "\n",
    "**Bonus Consideration**: Outside of the text itself, do other factors in the dataset have an effect? Do your results change if you include features like the airline or the timezone of the tweet?\n",
    "\n",
    "Don't forget to create a training and test set to compare your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['negative'] = df['airline_sentiment'].apply(lambda x: 1 if x=='negative' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.755009107468\n",
      "[[1687 2390]\n",
      " [ 300 6603]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.41      0.56      4077\n",
      "          1       0.73      0.96      0.83      6903\n",
      "\n",
      "avg / total       0.78      0.76      0.73     10980\n",
      "\n",
      "0.738524590164\n",
      "[[ 556  829]\n",
      " [ 128 2147]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.40      0.54      1385\n",
      "          1       0.72      0.94      0.82      2275\n",
      "\n",
      "avg / total       0.76      0.74      0.71      3660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'],\n",
    "                                                   df['negative'])\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(X_train)\n",
    "X_train_tf = tfidf.transform(X_train)\n",
    "\n",
    "tsvd = TruncatedSVD(n_components=100)\n",
    "tsvd.fit(X_train_tf)\n",
    "X_train_tf_tsvd = tsvd.transform(X_train_tf)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "rfc.fit(X_train_tf_tsvd, y_train)\n",
    "train_predictions = rfc.predict(X_train_tf_tsvd)\n",
    "print(rfc.score(X_train_tf_tsvd, y_train))\n",
    "print(confusion_matrix(y_train, train_predictions))\n",
    "print(classification_report(y_train, train_predictions))\n",
    "\n",
    "X_test_tf = tfidf.transform(X_test)\n",
    "X_test_tf_tsvd = tsvd.transform(X_test_tf)\n",
    "test_predictions = rfc.predict(X_test_tf_tsvd)\n",
    "print(rfc.score(X_test_tf_tsvd, y_test))\n",
    "print(confusion_matrix(y_test, test_predictions))\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
