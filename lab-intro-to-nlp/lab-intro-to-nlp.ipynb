{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to NLP Lab\n",
    "\n",
    "In this lab, you'll be classifying randomly selected tweets from political officials into whether or not they are partisan tweets or neutral. In the following import statement, we're selecting only the columns that are important, but there may be more useful features in that set. Feel free to explore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, \\\n",
    "HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_union, make_pipeline\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>partisan</td>\n",
       "      <td>RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>partisan</td>\n",
       "      <td>VIDEO - #Obamacare:  Full of Higher Costs and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Please join me today in remembering our fallen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @SenatorLeahy: 1st step toward Senate debat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>partisan</td>\n",
       "      <td>.@amazon delivery #drones show need to update ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bias                                               text\n",
       "0  partisan  RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...\n",
       "1  partisan  VIDEO - #Obamacare:  Full of Higher Costs and ...\n",
       "2   neutral  Please join me today in remembering our fallen...\n",
       "3   neutral  RT @SenatorLeahy: 1st step toward Senate debat...\n",
       "4  partisan  .@amazon delivery #drones show need to update ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('datasets/political_media.csv',\n",
    "                usecols=[7, 20])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "Please split the dataset into a training and test set and convert the `bias` feature into 0s and 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['bias'] = df['bias'].apply(lambda x: 1 if x == 'partisan' else 0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'].values,\n",
    "                                                   df['bias'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Please try the following techniques to transform the data. For each technique, do the following:\n",
    "\n",
    "1. Transform the training data\n",
    "2. Fit a `RandomForestClassifier` to the transformed training data\n",
    "3. Transform the test data\n",
    "4. Discuss the goodness of fit of your model using the test data and a classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. `CountVectorizer()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7176\n",
      "[[848  47]\n",
      " [306  49]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.95      0.83       895\n",
      "          1       0.51      0.14      0.22       355\n",
      "\n",
      "avg / total       0.67      0.72      0.65      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(X_train)\n",
    "\n",
    "X_train_cv = cv.transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_cv, y_train)\n",
    "print(rf.score(X_test_cv, y_test))\n",
    "predictions = rf.predict(X_test_cv)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. `CountVectorizer()` with your choice of `min_df` and `max_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6808\n",
      "[[796  99]\n",
      " [300  55]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.89      0.80       895\n",
      "          1       0.36      0.15      0.22       355\n",
      "\n",
      "avg / total       0.62      0.68      0.63      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=0.10, max_df=0.90)\n",
    "cv.fit(X_train)\n",
    "\n",
    "X_train_cv = cv.transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_cv, y_train)\n",
    "print(rf.score(X_test_cv, y_test))\n",
    "predictions = rf.predict(X_test_cv)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. `CountVectorizer()` with English stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7104\n",
      "[[815  80]\n",
      " [282  73]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.91      0.82       895\n",
      "          1       0.48      0.21      0.29       355\n",
      "\n",
      "avg / total       0.67      0.71      0.67      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "cv.fit(X_train)\n",
    "\n",
    "X_train_cv = cv.transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_cv, y_train)\n",
    "print(rf.score(X_test_cv, y_test))\n",
    "predictions = rf.predict(X_test_cv)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. `TfidfVectorizer()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272\n",
      "[[851  44]\n",
      " [297  58]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.95      0.83       895\n",
      "          1       0.57      0.16      0.25       355\n",
      "\n",
      "avg / total       0.69      0.73      0.67      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(X_train)\n",
    "\n",
    "X_train_tfidf = tfidf.transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "print(rf.score(X_test_tfidf, y_test))\n",
    "predictions = rf.predict(X_test_tfidf)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. `TfidfVectorizer()` with English stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716\n",
      "[[822  73]\n",
      " [282  73]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.92      0.82       895\n",
      "          1       0.50      0.21      0.29       355\n",
      "\n",
      "avg / total       0.68      0.72      0.67      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(X_train)\n",
    "\n",
    "X_train_tfidf = tfidf.transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "print(rf.score(X_test_tfidf, y_test))\n",
    "predictions = rf.predict(X_test_tfidf)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving forward\n",
    "\n",
    "With the remainder of your time, please try and find the best model and data transformation to predict partisan tweets. This is a challenging data set and can be approached from a number of ways.\n",
    "\n",
    "Some techniques to try are:\n",
    "\n",
    "1. Different types of data transformation \n",
    "2. Custom preprocessors for `CountVectorizer`\n",
    "3. Custom stopword lists\n",
    "4. Use of a dimensionality reduction technique (like `TruncatedSVD`)\n",
    "5. Optimizing hyperparameters using `GridSearchCV`\n",
    "6. Trying a different modeling technique such as `KNeighborsClassifier` or `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
