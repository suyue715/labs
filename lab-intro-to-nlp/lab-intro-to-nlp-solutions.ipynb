{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to NLP Lab\n",
    "\n",
    "In this lab, you'll be classifying randomly selected tweets from political officials into whether or not they are partisan tweets or neutral. In the following import statement, we're selecting only the columns that are important, but there may be more useful features in that set. Feel free to explore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>partisan</td>\n",
       "      <td>RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>partisan</td>\n",
       "      <td>VIDEO - #Obamacare:  Full of Higher Costs and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Please join me today in remembering our fallen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @SenatorLeahy: 1st step toward Senate debat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>partisan</td>\n",
       "      <td>.@amazon delivery #drones show need to update ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bias                                               text\n",
       "0  partisan  RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...\n",
       "1  partisan  VIDEO - #Obamacare:  Full of Higher Costs and ...\n",
       "2   neutral  Please join me today in remembering our fallen...\n",
       "3   neutral  RT @SenatorLeahy: 1st step toward Senate debat...\n",
       "4  partisan  .@amazon delivery #drones show need to update ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/political_media.csv',\n",
    "                usecols=[7, 20])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "Please split the dataset into a training and test set and convert the `bias` feature into 0s and 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['bias'] = df['bias'].apply(lambda x: 1 if x == 'partisan' else 0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'].values,\n",
    "                                                   df['bias'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Please try the following techniques to transform the data. For each technique, do the following:\n",
    "\n",
    "1. Transform the training data\n",
    "2. Fit a `RandomForestClassifier` to the transformed training data\n",
    "3. Transform the test data\n",
    "4. Discuss the goodness of fit of your model using the test data and a classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. `CountVectorizer()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7552\n",
      "[[895  33]\n",
      " [273  49]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.96      0.85       928\n",
      "          1       0.60      0.15      0.24       322\n",
      "\n",
      "avg / total       0.72      0.76      0.70      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(X_train)\n",
    "\n",
    "X_train_cv = cv.transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_cv, y_train)\n",
    "print(rf.score(X_test_cv, y_test))\n",
    "predictions = rf.predict(X_test_cv)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. `CountVectorizer()` with your choice of `min_df` and `max_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716\n",
      "[[841  87]\n",
      " [268  54]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.91      0.83       928\n",
      "          1       0.38      0.17      0.23       322\n",
      "\n",
      "avg / total       0.66      0.72      0.67      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=0.10, max_df=0.90)\n",
    "cv.fit(X_train)\n",
    "\n",
    "X_train_cv = cv.transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_cv, y_train)\n",
    "print(rf.score(X_test_cv, y_test))\n",
    "predictions = rf.predict(X_test_cv)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. `CountVectorizer()` with English stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748\n",
      "[[868  60]\n",
      " [255  67]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.94      0.85       928\n",
      "          1       0.53      0.21      0.30       322\n",
      "\n",
      "avg / total       0.71      0.75      0.71      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "cv.fit(X_train)\n",
    "\n",
    "X_train_cv = cv.transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_cv, y_train)\n",
    "print(rf.score(X_test_cv, y_test))\n",
    "predictions = rf.predict(X_test_cv)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. `TfidfVectorizer()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7488\n",
      "[[870  58]\n",
      " [256  66]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.94      0.85       928\n",
      "          1       0.53      0.20      0.30       322\n",
      "\n",
      "avg / total       0.71      0.75      0.71      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(X_train)\n",
    "\n",
    "X_train_tfidf = tfidf.transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "print(rf.score(X_test_tfidf, y_test))\n",
    "predictions = rf.predict(X_test_tfidf)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. `TfidfVectorizer()` with English stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7472\n",
      "[[861  67]\n",
      " [249  73]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.93      0.84       928\n",
      "          1       0.52      0.23      0.32       322\n",
      "\n",
      "avg / total       0.71      0.75      0.71      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(X_train)\n",
    "\n",
    "X_train_tfidf = tfidf.transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "print(rf.score(X_test_tfidf, y_test))\n",
    "predictions = rf.predict(X_test_tfidf)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving forward\n",
    "\n",
    "With the remainder of your time, please try and find the best model and data transformation to predict partisan tweets. This is a challenging data set and can be approached from a number of ways.\n",
    "\n",
    "Some techniques to try are:\n",
    "\n",
    "1. Different types of data transformation \n",
    "2. Custom preprocessors for `CountVectorizer`\n",
    "3. Custom stopword lists\n",
    "4. Use of a dimensionality reduction technique (like `TruncatedSVD`)\n",
    "5. Optimizing hyperparameters using `GridSearchCV`\n",
    "6. Trying a different modeling technique such as `KNeighborsClassifier` or `LogisticRegression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Instructor answer:\n",
    "\n",
    "This section is exceptionally open ended. Please challenge yourself to try multiple techniques and compare the results.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
